{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "R_mOBdRxcWyB"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import string\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import SGDClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxT-Sh4CVCbZ",
        "outputId": "31914eb4-b8f0-40e1-9dcc-d4f05e6b066d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\alkal\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\alkal\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "boCkJm41cp8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'none'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# death_row_fn = 'gdrive/My Drive/COEN140/group-project/data/Last-Statement-of-Death-Row.csv'\n",
        "# suicide_depression_fn = 'gdrive/My Drive/COEN140/group-project/data/reddit_depression_suicidewatch.csv'\n",
        "# hate_fn = 'gdrive/My Drive/COEN140/group-project/data/Dynamically_Generated_Hate_Dataset_v0.2.3.csv'\n",
        "# sentiment_fn = 'gdrive/My Drive/COEN140/group-project/data/sentiment.csv'\n",
        "# output_fn = 'gdrive/My Drive/COEN140/group-project/data/output.dat'\n",
        "\n",
        "#read train.csv file into dataframe\n",
        "#data was pre-processed, cleaned in 'data_collection.ipynb'\n",
        "data = pd.read_csv('train.csv', header=0)\n",
        "df = data.iloc[:,1:]\n",
        "df.dropna() #drop empty rows from dataframe\n",
        "#fixes bug: thinks row 82162 is nan which messes up the pre-processing\n",
        "df.iloc[82162,0] = \"none\"\n",
        "df.iloc[82162,0]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "izyMJoa61qR6"
      },
      "source": [
        "Class labels are \n",
        "\n",
        "0 - Neutral \n",
        "\n",
        "1 - Hate\n",
        "\n",
        "2 - Depression\n",
        "\n",
        "3 - Suicidal"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TCEdPNwIU5fa"
      },
      "source": [
        "# Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zjsvL2N8UnNL"
      },
      "outputs": [],
      "source": [
        "# split feature matrix and target values\n",
        "docs = df['text']\n",
        "classes = df['class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "L5XWwOJTNHCQ"
      },
      "outputs": [],
      "source": [
        "# split each text sample into seperate words \n",
        "docs_mat = [word_tokenize(text) for text in docs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fjssRgvhU4X3"
      },
      "outputs": [],
      "source": [
        "sw_nltk = stopwords.words('english')\n",
        "s = PorterStemmer()\n",
        "def preprocess_docs(docs): \n",
        "  ''' Taking a matrix of documents with words in each document, \n",
        "  preprocess the matrix by removing punctuation, words less than 4 letters, \n",
        "  and stop words and return the preprocessed matrix. '''\n",
        "\n",
        "  docs = [ [ s.stem(word) for word in sample if (word not in string.punctuation) and len(word) >= 4 and (word.lower() not in sw_nltk)] for sample in docs]\n",
        "  return docs \n",
        "\n",
        "pp_docs = preprocess_docs(docs_mat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fxIkHRaMrhwt"
      },
      "outputs": [],
      "source": [
        "def truncate(docs, classes): \n",
        "  # standardize each sample to have the same number of words \n",
        "  trunc = int(np.mean([len(d) for d in docs]))\n",
        "\n",
        "  return [ (' '.join(docs[i][:trunc]), classes[i]) for i in range(len(docs)) if len(docs[i]) >= trunc]\n",
        "\n",
        "\n",
        "trunc = truncate(pp_docs, classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aFCorDXx30Pq"
      },
      "outputs": [],
      "source": [
        "trunc_docs = [t[0] for t in trunc]\n",
        "trunc_classes = [t[1] for t in trunc]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "y1sANCmKS68D"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(list,\n",
              " str,\n",
              " 'distil gasif wast inciner method accord present invent distil gasif wast inciner method plural distil furnac provid combust furnac wast held distil furnac dry-distil sequenc therebi produc combust control carri temperatur combust furnac becom predetermin first temperatur case combust introduc combust furnac burnt method includ step suppli oxygen requir distil wast first distil furnac control degre open first valv provid first oxygen suppli passag temperatur combust furnac becom first temperatur combust combust case combust produc dry-distil wast held first distil furnac use oxygen suppli first distil furnac first oxygen suppli passag oxygen suppli sourc combust introduc combust furnac burnt step detect presenc wast second distil furnac control carri temperatur combust furnac becom first temperatur combust combust produc first distil furnac ignit wast held second distil furnac use oxygen suppli second distil furnac second oxygen suppli passag oxygen suppli sourc step dry-distil wast held second distil furnac use oxygen suppli second distil furnac second oxygen suppli passag oxygen suppli sourc produc combust introduc combust produc second distil furnac combust furnac start combust distil gasif wast inciner method accord present invent first combust produc first distil furnac dry-distil wast held furnac use oxygen suppli')"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_train, docs_test, cls_train, cls_test = train_test_split(trunc_docs, trunc_classes, train_size=0.7, test_size=0.3 , shuffle=True, random_state=1)\n",
        "type(docs_train), type(docs_train[0]), docs_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "BugnJ-JRfRaQ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(list,\n",
              " list,\n",
              " ['distil',\n",
              "  'gasif',\n",
              "  'wast',\n",
              "  'inciner',\n",
              "  'method',\n",
              "  'accord',\n",
              "  'present',\n",
              "  'invent',\n",
              "  'distil',\n",
              "  'gasif',\n",
              "  'wast',\n",
              "  'inciner',\n",
              "  'method',\n",
              "  'plural',\n",
              "  'distil',\n",
              "  'furnac',\n",
              "  'provid',\n",
              "  'combust',\n",
              "  'furnac',\n",
              "  'wast',\n",
              "  'held',\n",
              "  'distil',\n",
              "  'furnac',\n",
              "  'dry-distil',\n",
              "  'sequenc',\n",
              "  'therebi',\n",
              "  'produc',\n",
              "  'combust',\n",
              "  'control',\n",
              "  'carri',\n",
              "  'temperatur',\n",
              "  'combust',\n",
              "  'furnac',\n",
              "  'becom',\n",
              "  'predetermin',\n",
              "  'first',\n",
              "  'temperatur',\n",
              "  'case',\n",
              "  'combust',\n",
              "  'introduc',\n",
              "  'combust',\n",
              "  'furnac',\n",
              "  'burnt',\n",
              "  'method',\n",
              "  'includ',\n",
              "  'step',\n",
              "  'suppli',\n",
              "  'oxygen',\n",
              "  'requir',\n",
              "  'distil',\n",
              "  'wast',\n",
              "  'first',\n",
              "  'distil',\n",
              "  'furnac',\n",
              "  'control',\n",
              "  'degre',\n",
              "  'open',\n",
              "  'first',\n",
              "  'valv',\n",
              "  'provid',\n",
              "  'first',\n",
              "  'oxygen',\n",
              "  'suppli',\n",
              "  'passag',\n",
              "  'temperatur',\n",
              "  'combust',\n",
              "  'furnac',\n",
              "  'becom',\n",
              "  'first',\n",
              "  'temperatur',\n",
              "  'combust',\n",
              "  'combust',\n",
              "  'case',\n",
              "  'combust',\n",
              "  'produc',\n",
              "  'dry-distil',\n",
              "  'wast',\n",
              "  'held',\n",
              "  'first',\n",
              "  'distil',\n",
              "  'furnac',\n",
              "  'use',\n",
              "  'oxygen',\n",
              "  'suppli',\n",
              "  'first',\n",
              "  'distil',\n",
              "  'furnac',\n",
              "  'first',\n",
              "  'oxygen',\n",
              "  'suppli',\n",
              "  'passag',\n",
              "  'oxygen',\n",
              "  'suppli',\n",
              "  'sourc',\n",
              "  'combust',\n",
              "  'introduc',\n",
              "  'combust',\n",
              "  'furnac',\n",
              "  'burnt',\n",
              "  'step',\n",
              "  'detect',\n",
              "  'presenc',\n",
              "  'wast',\n",
              "  'second',\n",
              "  'distil',\n",
              "  'furnac',\n",
              "  'control',\n",
              "  'carri',\n",
              "  'temperatur',\n",
              "  'combust',\n",
              "  'furnac',\n",
              "  'becom',\n",
              "  'first',\n",
              "  'temperatur',\n",
              "  'combust',\n",
              "  'combust',\n",
              "  'produc',\n",
              "  'first',\n",
              "  'distil',\n",
              "  'furnac',\n",
              "  'ignit',\n",
              "  'wast',\n",
              "  'held',\n",
              "  'second',\n",
              "  'distil',\n",
              "  'furnac',\n",
              "  'use',\n",
              "  'oxygen',\n",
              "  'suppli',\n",
              "  'second',\n",
              "  'distil',\n",
              "  'furnac',\n",
              "  'second',\n",
              "  'oxygen',\n",
              "  'suppli',\n",
              "  'passag',\n",
              "  'oxygen',\n",
              "  'suppli',\n",
              "  'sourc',\n",
              "  'step',\n",
              "  'dry-distil',\n",
              "  'wast',\n",
              "  'held',\n",
              "  'second',\n",
              "  'distil',\n",
              "  'furnac',\n",
              "  'use',\n",
              "  'oxygen',\n",
              "  'suppli',\n",
              "  'second',\n",
              "  'distil',\n",
              "  'furnac',\n",
              "  'second',\n",
              "  'oxygen',\n",
              "  'suppli',\n",
              "  'passag',\n",
              "  'oxygen',\n",
              "  'suppli',\n",
              "  'sourc',\n",
              "  'produc',\n",
              "  'combust',\n",
              "  'introduc',\n",
              "  'combust',\n",
              "  'produc',\n",
              "  'second',\n",
              "  'distil',\n",
              "  'furnac',\n",
              "  'combust',\n",
              "  'furnac',\n",
              "  'start',\n",
              "  'combust',\n",
              "  'distil',\n",
              "  'gasif',\n",
              "  'wast',\n",
              "  'inciner',\n",
              "  'method',\n",
              "  'accord',\n",
              "  'present',\n",
              "  'invent',\n",
              "  'first',\n",
              "  'combust',\n",
              "  'produc',\n",
              "  'first',\n",
              "  'distil',\n",
              "  'furnac',\n",
              "  'dry-distil',\n",
              "  'wast',\n",
              "  'held',\n",
              "  'furnac',\n",
              "  'use',\n",
              "  'oxygen',\n",
              "  'suppli'])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#split all of the words in the samples within the train and test documents\n",
        "docs_train2 = [doc.split() for doc in docs_train]\n",
        "docs_test2 = [doc.split() for doc in docs_test]\n",
        "type(docs_train2), type(docs_train2[0]), docs_train2[0]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tJZ-6HKRQckW"
      },
      "source": [
        "# Model Selection "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kiIpR_vcUKnv"
      },
      "outputs": [],
      "source": [
        "def score_models(models, docs_train, cls_train): \n",
        "  scores = []\n",
        "  for m in models: \n",
        "\n",
        "    # take the average accuracy score for the model across k-fold cross validation\n",
        "    scores.append((m, np.mean(cross_val_score(m, X=docs_train, y=cls_train, scoring='accuracy'))))\n",
        "  \n",
        "  # sort the scores by the model with the highest accuracy \n",
        "  scores.sort(key=lambda x: x[1], reverse=True)\n",
        "  return scores "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zw1UJC8i3RUg"
      },
      "source": [
        "Support Vector Machine (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMdUeMbf3RGK",
        "outputId": "b344ddc1-c367-4633-d1c3-edc562154d75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(SGDClassifier(alpha=0.001, max_iter=5, random_state=0, tol=None),\n",
              "  0.9869172758263914)]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer())])\n",
        "\n",
        "#the model was not functioning properly when passing in docs_train after splitting all of the words in the samples\n",
        "score_models([SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=0, max_iter=5, tol=None)], pipe.fit_transform(docs_train), cls_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssM7bOa_3pvl"
      },
      "outputs": [],
      "source": [
        "# def get_best_svm(): \n",
        "  \n",
        "#   # linear SVM with stochastic gradient descent \n",
        "#   svm_models = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=0, max_iter=5, tol=None)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "b-hyP40q24Gs"
      },
      "source": [
        "Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "rdsaYgbw26h7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(MultinomialNB(), 0.9910185964517945)]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "pipe = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer())])\n",
        "\n",
        "#the model was not functioning properly when passing in docs_train after splitting all of the words in the samples\n",
        "score_models([MultinomialNB()], pipe.fit_transform(docs_train), cls_train)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8XgP58ClR4-b"
      },
      "source": [
        "Classic Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "bfcR4a-aT1Zg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(DecisionTreeClassifier(max_depth=10, min_impurity_decrease=0, random_state=0),\n",
              " 0.9898765752516077)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer())])\n",
        "\n",
        "docs_train3 = pipe.fit_transform(docs_train)\n",
        "\n",
        "\n",
        "def get_best_dtc(): \n",
        "  depth_range = (None, 1, 10, 20, 50)\n",
        "  leaf_samples_range = (1, 10, 20, 50)\n",
        "  impurity_decrease_range = range(0,5)\n",
        "  dtc_models = [  DecisionTreeClassifier(random_state=0, max_depth=d, min_samples_leaf=l, min_impurity_decrease=i) \n",
        "  for i in impurity_decrease_range  \n",
        "  for l in leaf_samples_range \n",
        "  for d in depth_range ]\n",
        "\n",
        "  return score_models(dtc_models, docs_train3, cls_train)\n",
        "\n",
        "\n",
        "\n",
        "scores = get_best_dtc()\n",
        "scores[0]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
